{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tablar_nov_2021_(2).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOxsYE2ceInHN5uaAXnsI8n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riotamoriya/kaggle/blob/main/tablar_nov_2021_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nilBFOaj9mI",
        "outputId": "2eff2aa3-a04f-4a9e-e7ae-f6ed371dc66f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#@title Set the environment\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "import numpy as np # linear algebra\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import csv\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "import sys\n",
        "import gc\n",
        "\n",
        "pd.options.display.max_rows = 1000\n",
        "pd.options.display.max_columns = 20\n",
        "\n",
        "from pathlib import Path\n",
        "if 'google.colab' in sys.modules:  # colab環境\n",
        "    INPUT = Path('/content/input/')\n",
        "elif 'kaggle_web_client' in sys.modules:  # kaggle環境\n",
        "    INPUT = Path('../input/')\n",
        "\n",
        "# メタ情報を取得\n",
        "from requests import get\n",
        "name_notebook = get('http://172.28.0.2:9000/api/sessions').json()[0]['name']\n",
        "print(name_notebook)\n",
        "\n",
        "# google drive と接続\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# gdriveにある自分のライブラリ読み込み\n",
        "from drive.MyDrive.Kaggle_emwa.myPythonLib import send_line_notify as sln\n",
        "\n",
        "\n",
        "# kaggleと接続\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/drive/MyDrive/Kaggle_emwa/kaggle.json ~/.kaggle\n",
        "!pip install kaggle\n",
        "!pip install --upgrade --force-reinstall --no-deps kaggle\n",
        "# !kaggle competitions list"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tablar_nov_2021_(2).ipynb\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Collecting kaggle\n",
            "  Using cached kaggle-1.5.12-py3-none-any.whl\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.5.12\n",
            "    Uninstalling kaggle-1.5.12:\n",
            "      Successfully uninstalled kaggle-1.5.12\n",
            "Successfully installed kaggle-1.5.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc5QCdtcqOPc"
      },
      "source": [
        "tryproblem = 'tabular-playground-series-nov-2021'\n",
        "tryproblem += '.zip'\n",
        "\n",
        "\n",
        "if not os.path.exists(tryproblem):\n",
        "  !kaggle competitions download -c tabular-playground-series-nov-2021\n",
        "  import zipfile\n",
        "  with zipfile.ZipFile(tryproblem) as existing_zip:\n",
        "      existing_zip.extractall('.')\n",
        "row_train = pd.read_csv('./train.csv')\n",
        "row_test = pd.read_csv('./test.csv')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNVyMRLg_YWG"
      },
      "source": [
        "train = row_train.drop(['id','target'], axis = 1)\n",
        "test = row_test.drop('id', axis = 1)\n",
        "\n",
        "target = row_train.target\n",
        "id_train = row_train.id\n",
        "id_test = row_test.id\n",
        "\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# Some parameters to config \n",
        "\n",
        "EPOCHS = 700\n",
        "BATCH_SIZE = 2048 \n",
        "ACTIVATION = 'swish'\n",
        "LEARNING_RATE = 0.0007\n",
        "FOLDS = 5"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_nKIwd5AqQU"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "# the number 2 is just a threshold to split \n",
        "h_skew = train.loc[:,train.skew() >= 2].columns  # with Skewed \n",
        "l_skew = train.loc[:,train.skew() < 2].columns   # Bimodal\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# Skewed distrubutions\n",
        "\n",
        "# train['mean_h'] = train[h_skew].mean(axis=1)\n",
        "# test['mean_h'] = test[h_skew].mean(axis=1)\n",
        "\n",
        "# train['std_h'] = np.log1p(train[h_skew].std(axis=1))\n",
        "# test['std_h'] = np.log1p(test[h_skew].std(axis=1))\n",
        "\n",
        "train['median_h'] = train[h_skew].median(axis=1)\n",
        "test['median_h'] = test[h_skew].median(axis=1)\n",
        "\n",
        "# train['min_h'] = train[h_skew].min(axis=1)\n",
        "# test['min_h'] = test[h_skew].min(axis=1)\n",
        "\n",
        "# train['skew_h'] = train[h_skew].skew(axis=1)\n",
        "# test['skew_h'] = test[h_skew].skew(axis=1)\n",
        "\n",
        "# train['max_h'] = train[h_skew].max(axis=1)\n",
        "# test['max_h'] = test[h_skew].max(axis=1)\n",
        "\n",
        "train['var_h'] = train[h_skew].var(axis=1)\n",
        "test['var_h'] = test[h_skew].var(axis=1)\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# Bimodal distributions\n",
        "\n",
        "train['mean_l'] = train[l_skew].mean(axis=1)\n",
        "test['mean_l'] = test[l_skew].mean(axis=1)\n",
        "\n",
        "train['std_l'] = train[l_skew].std(axis=1)\n",
        "test['std_l'] = test[l_skew].std(axis=1)\n",
        "\n",
        "train['median_l'] = train[l_skew].median(axis=1)\n",
        "test['median_l'] = test[l_skew].median(axis=1)\n",
        "\n",
        "# train['min_l'] = train[l_skew].min(axis=1)\n",
        "# test['min_l'] = test[l_skew].min(axis=1)\n",
        "\n",
        "train['skew_l'] = train[l_skew].skew(axis=1)\n",
        "test['skew_l'] = test[l_skew].skew(axis=1)\n",
        "\n",
        "train['max_l'] = train[l_skew].max(axis=1)\n",
        "test['max_l'] = test[l_skew].max(axis=1)\n",
        "\n",
        "train['var_l'] = train[l_skew].var(axis=1)\n",
        "test['var_l'] = test[l_skew].var(axis=1)\n",
        "\n",
        "\n",
        "raw_train = train.copy()\n",
        "raw_test = test.copy()\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# Scaling and Nomalization\n",
        "\n",
        "transformer_high_skew = make_pipeline(\n",
        "    StandardScaler(), \n",
        "    MinMaxScaler(feature_range=(0, 1))\n",
        ")\n",
        "\n",
        "transformer_low_skew = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    MinMaxScaler(feature_range=(0, 1))\n",
        ")\n",
        "\n",
        "new_cols = train.columns[-8:]\n",
        "\n",
        "transformer_new_cols = make_pipeline(\n",
        "    StandardScaler(),\n",
        "    MinMaxScaler(feature_range=(0, 1))\n",
        ")\n",
        "\n",
        "preprocessor = make_column_transformer(\n",
        "    (transformer_high_skew, l_skew),\n",
        "    (transformer_low_skew, h_skew),\n",
        "    (transformer_new_cols, new_cols),\n",
        ")"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B-8Qym2At4f"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import callbacks\n",
        "\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# Seed \n",
        "\n",
        "my_seed = 42\n",
        "def seedAll(seed):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    \n",
        "seedAll(my_seed)\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "def load_model(name:str):\n",
        "    \n",
        "    early_stopping = callbacks.EarlyStopping(\n",
        "        patience=20,\n",
        "        min_delta=0,\n",
        "        monitor='val_loss',\n",
        "        restore_best_weights=True,\n",
        "        verbose=0,\n",
        "        mode='min', \n",
        "        baseline=None,\n",
        "    )\n",
        "\n",
        "    plateau = callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss', \n",
        "            factor=0.2, \n",
        "            patience=7, \n",
        "            verbose=0,\n",
        "            mode='min')\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "# Model \n",
        "\n",
        "    model = keras.Sequential([\n",
        "        layers.Dense(108, activation = ACTIVATION, input_shape = [train.shape[1]]),      \n",
        "        layers.Dense(64, activation =ACTIVATION), \n",
        "        layers.Dense(32, activation =ACTIVATION),\n",
        "        layers.Dense(1, activation='sigmoid'),\n",
        "    ])\n",
        "\n",
        "# -----------------------------------------------------------------\n",
        "\n",
        "    model.compile(\n",
        "        optimizer= keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['AUC'],\n",
        "    )\n",
        "    \n",
        "    return model, early_stopping, plateau"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxquermDDECY"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score, log_loss\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer\n",
        "\n",
        "preds_valid_f = {}\n",
        "preds_test = []\n",
        "total_auc = []\n",
        "f_scores = []\n",
        "\n",
        "kf = StratifiedKFold(n_splits=FOLDS,random_state=0,shuffle=True)\n",
        "\n",
        "for fold,(train_index, valid_index) in enumerate(kf.split(train,target)):\n",
        "\n",
        "    X_train,X_valid = train.loc[train_index], train.loc[valid_index]\n",
        "    y_train,y_valid = target.loc[train_index], target.loc[valid_index]\n",
        "\n",
        "    #   --------------------------------------------------------  \n",
        "    # Preprocessing\n",
        "    index_valid  = X_valid.index.tolist()\n",
        "    test  = raw_test.copy()\n",
        "    \n",
        "    X_train = preprocessor.fit_transform(X_train)\n",
        "    X_valid = preprocessor.transform(X_valid)\n",
        "    test = preprocessor.transform(test)\n",
        "    \n",
        "    #  ----------------------------------------------------------    \n",
        "    # Model\n",
        "    \n",
        "    model, early_stopping, plateau  = load_model('version1')\n",
        "\n",
        "    history = model.fit(  X_train, y_train,\n",
        "                validation_data = (X_valid, y_valid),\n",
        "                batch_size = BATCH_SIZE, \n",
        "                epochs = EPOCHS,\n",
        "                callbacks = [early_stopping, plateau],\n",
        "                shuffle = True,\n",
        "                verbose = 0\n",
        "              )\n",
        "\n",
        "    #  ----------------------------------------------------------\n",
        "    #  oof\n",
        "    preds_valid = model.predict(X_valid).reshape(1,-1)[0] \n",
        "    \n",
        "    #  ----------------------------------------------------------\n",
        "    #  test  predictions\n",
        "    preds_test.append(model.predict(test).reshape(1,-1)[0])\n",
        "    \n",
        "    #  ----------------------------------------------------------\n",
        "    #  Saving  scores to plot the end  \n",
        "    scores = pd.DataFrame(history.history)\n",
        "    scores['folds'] = fold\n",
        "    \n",
        "    if fold == 0:\n",
        "        f_scores = scores \n",
        "    else: \n",
        "        f_scores = pd.concat([f_scores, scores], axis  = 0)\n",
        "        \n",
        "    #  ----------------------------------------------------------\n",
        "    #  concatenating valid preds\n",
        "    preds_valid_f.update(dict(zip(index_valid, preds_valid)))\n",
        "\n",
        "    # Getting score for a fold model\n",
        "    fold_auc = roc_auc_score(y_valid, preds_valid)\n",
        "    print(f\"Fold {fold} roc_auc_score: {fold_auc}\")\n",
        "\n",
        "    # Total auc\n",
        "    total_auc.append(fold_auc)\n",
        "\n",
        "print(f\"mean roc_auc_score: {np.mean(total_auc)}, std: {np.std(total_auc)}\")\n",
        "sln(\"finish the fitting\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0qIJWVVDRQS"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for fold in range(f_scores['folds'].nunique()):\n",
        "    history_f = f_scores[f_scores['folds'] == fold]\n",
        "\n",
        "    fig, ax = plt.subplots(1, 2, tight_layout=True, figsize=(14,4))\n",
        "    fig.suptitle('Fold : '+str(fold), fontsize=14)\n",
        "        \n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history_f.loc[:, ['loss', 'val_loss']], label= ['loss', 'val_loss'])\n",
        "    plt.legend(fontsize=15)\n",
        "    plt.grid()\n",
        "    \n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history_f.loc[:, ['auc', 'val_auc']],label= ['auc', 'val_auc'])\n",
        "    plt.legend(fontsize=15)\n",
        "    plt.grid()\n",
        "    \n",
        "    print(\"Validation Loss: {:0.4f}\".format(history_f['val_loss'].min()));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DDMJvDEDWA4"
      },
      "source": [
        "sub = pd.read_csv(\"../input/tabular-playground-series-nov-2021/sample_submission.csv\")\n",
        "sub['target'] = np.mean(preds_test, axis = 0)\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "sub.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}